{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Code reference Google results count Extract results count from Google with beautiful soup Methods take a list of keywords and return a dataframe. assert_google_results ( df , keyword_list , url = 'https://www.google.com/search?q=' ) Ensures that dataframe meets expectations Source code in src\\data\\gresults_extract.py def assert_google_results ( df , keyword_list , url = \"https://www.google.com/search?q=\" ): \"\"\"Ensures that dataframe meets expectations \"\"\" # expected dataframe for comparison df_compare = pd . DataFrame ({ 'keyword' : pd . Series ([ * keyword_list ], dtype = 'object' ), 'results_count' : pd . Series ([ 1 for i in keyword_list ], dtype = 'int64' ), 'search_url' : pd . Series ( create_search_url ( keyword_list , url = url ), dtype = 'object' ), 'query_timestamp' : pd . Series ([ datetime . now () for i in keyword_list ], dtype = 'datetime64[ns]' ) }) # comparison to actual column_difference = set ( df . columns ) . symmetric_difference ( df_compare . columns ) assert len ( column_difference ) == 0 , f \"The following columns differ to reference dataframe: { column_difference } \" assert ( df_compare . dtypes == df . dtypes ) . all (), f \"Different dtypes for { df . dtypes } \\n { df_compare . dtypes } \" assert len ( df ) == len ( keyword_list ), f \" { len ( df ) } does not equal { len ( keyword_list ) } \" logging . info ( \"Google results data meets expectations\" ) create_search_url ( keyword_list , url = 'https://www.google.com/search?q=' ) Create Google search URL for a keyword from keyword_list Parameters: Name Type Description Default keyword_list list list of strings that contain the search keywords required url str Google's base search url 'https://www.google.com/search?q=' Returns: Type Description list Google search url like https://www.google.com/search?q=pizza Source code in src\\data\\gresults_extract.py def create_search_url ( keyword_list , url = \"https://www.google.com/search?q=\" ): \"\"\"Create Google search URL for a keyword from keyword_list Args: keyword_list (list): list of strings that contain the search keywords url (str): Google's base search url Returns: list: Google search url like https://www.google.com/search?q=pizza \"\"\" search_query = [ kw . replace ( ' ' , '+' ) for kw in keyword_list ] # replace space with '+' return [ url + sq for sq in search_query ] get_results_count ( keyword , user_agent ) Gets Google's result count for a keyword Parameters: Name Type Description Default keyword string The keyword for which to get the results count required user_agent string For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} required Returns: Type Description int Results count Source code in src\\data\\gresults_extract.py def get_results_count ( keyword , user_agent ): \"\"\"Gets Google's result count for a keyword Args: keyword (string): The keyword for which to get the results count user_agent (string): For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} Returns: int: Results count \"\"\" result = requests . get ( keyword , headers = user_agent ) soup = BeautifulSoup ( result . content , 'html.parser' ) # string that contains results count 'About 1,410,000,000 results' total_results_text = soup . find ( \"div\" , { \"id\" : \"result-stats\" }) . find ( text = True , recursive = False ) # extract number results_num = int ( '' . join ([ num for num in total_results_text if num . isdigit ()]) ) return results_num get_results_count_pipeline ( keyword_list , user_agent , url = 'https://www.google.com/search?q=' ) Google results count for each keyword of keyword_list in a dataframe Parameters: Name Type Description Default keyword_list list The keywords for which to get the results count required user_agent string For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} required url string Google's base search URL like \"https://www.google.com/search?q=\" (default) 'https://www.google.com/search?q=' Returns: Type Description dataframe Google results count and query metadata Examples: with open('../settings.yaml') as file: config = yaml.full_load(file) user_agent = config['query']['google_results']['user_agent'] base_url = config['query']['google_results']['base_url'] keyword_list = ['pizza', 'lufthansa'] result_counts = get_results_count_pipeline(keyword_list, user_agent, base_url) Source code in src\\data\\gresults_extract.py def get_results_count_pipeline ( keyword_list , user_agent , url = \"https://www.google.com/search?q=\" ): \"\"\"Google results count for each keyword of keyword_list in a dataframe Args: keyword_list (list): The keywords for which to get the results count user_agent (string): For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} url (string): Google's base search URL like \"https://www.google.com/search?q=\" (default) Returns: dataframe: Google results count and query metadata Examples: with open('../settings.yaml') as file: config = yaml.full_load(file) user_agent = config['query']['google_results']['user_agent'] base_url = config['query']['google_results']['base_url'] keyword_list = ['pizza', 'lufthansa'] result_counts = get_results_count_pipeline(keyword_list, user_agent, base_url) \"\"\" search_urls = create_search_url ( keyword_list ) result_count = [ get_results_count ( url , user_agent ) for url in search_urls ] df = pd . DataFrame ({ 'keyword' : keyword_list , 'results_count' : result_count , 'search_url' : search_urls , 'query_timestamp' : datetime . now ()}) # testing assert_google_results ( df = df , keyword_list = keyword_list , url = url ) return df Google trends Extract data from Google trends with the pytrends package methods take one keyword, call pytrends and return raw data create_pytrends_session () Create pytrends TrendReq() session on which .build_payload() can be called Source code in src\\data\\gtrends_extract.py def create_pytrends_session (): \"\"\"Create pytrends TrendReq() session on which .build_payload() can be called \"\"\" pytrends_session = TrendReq () return pytrends_session create_related_queries_dataframe ( response , rankings , keywords , geo_description = 'global' ) Returns a single dataframe of related queries for a list of keywords and each ranking (either 'top' or 'rising') Source code in src\\data\\gtrends_extract.py def create_related_queries_dataframe ( response , rankings , keywords , geo_description = 'global' ): \"\"\"Returns a single dataframe of related queries for a list of keywords and each ranking (either 'top' or 'rising') \"\"\" df_list = [] for r in rankings : for kw in keywords : df_list . append ( process_response ( response , kw = kw , ranking = r , geo = geo_description )) return pd . concat ( df_list ) get_related_queries ( pytrends_session , keyword_list , cat = 0 , geo = '' ) Returns a dictionary with a dataframe for each keyword Calls pytrend's related_queries() Parameters: Name Type Description Default pytrends_session object TrendReq() session of pytrend required keyword_list list Used as input for query and passed to TrendReq().build_payload() required cat int see https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories 0 geo str Geolocation like US, UK '' Returns: Type Description Dictionary Dict with dataframes with related query results Source code in src\\data\\gtrends_extract.py def get_related_queries ( pytrends_session , keyword_list , cat = 0 , geo = '' ): \"\"\"Returns a dictionary with a dataframe for each keyword Calls pytrend's related_queries() Args: pytrends_session (object): TrendReq() session of pytrend keyword_list (list): Used as input for query and passed to TrendReq().build_payload() cat (int): see https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories geo (str): Geolocation like US, UK Returns: Dictionary: Dict with dataframes with related query results \"\"\" assert isinstance ( keyword_list , list ), f \"keyword_list should be string. Instead of type { type ( keyword_list ) } \" df_related_queries = pd . DataFrame () try : pytrends_session . build_payload ( keyword_list , cat = cat , geo = geo ) df_related_queries = pytrends_session . related_queries () logging . info ( f \"Query succeeded for { * keyword_list , } \" ) except Exception as e : logging . error ( f \"Query not unsuccessful due to { e } . Return empty DataFrame.\" ) return df_related_queries get_related_queries_pipeline ( pytrends_session , keyword_list , cat = 0 , geo = '' , geo_description = 'global' ) Returns all response data for pytrend's .related_queries() in a single dataframe Example usage: pytrends_session = create_pytrends_session() df = get_related_queries_pipeline(pytrends_session, keyword_list=['pizza', 'lufthansa']) Source code in src\\data\\gtrends_extract.py def get_related_queries_pipeline ( pytrends_session , keyword_list , cat = 0 , geo = '' , geo_description = 'global' ): \"\"\"Returns all response data for pytrend's .related_queries() in a single dataframe Example usage: pytrends_session = create_pytrends_session() df = get_related_queries_pipeline(pytrends_session, keyword_list=['pizza', 'lufthansa']) \"\"\" response = get_related_queries ( pytrends_session = pytrends_session , keyword_list = keyword_list , cat = cat , geo = geo ) # response , rankings , keywords = unpack_related_queries_response ( response = response ) df_trends = create_related_queries_dataframe ( response = response , rankings = rankings , keywords = keywords , geo_description = geo_description ) return df_trends process_response ( response , kw , geo , ranking ) Helper function for unpack_related_queries_response() Source code in src\\data\\gtrends_extract.py def process_response ( response , kw , geo , ranking ): \"\"\" Helper function for unpack_related_queries_response() \"\"\" try : df = response [ kw ][ ranking ] df [[ 'keyword' , 'ranking' , 'geo' , 'query_timestamp' ]] = [ kw , ranking , geo , datetime . now ()] except : logging . info ( f \"Append empty dataframe for { ranking } : { kw } \" ) return pd . DataFrame ( columns = [ 'query' , 'value' , 'keyword' , 'ranking' , 'geo' , 'query_timestamp' ]) return df unpack_related_queries_response ( response ) Unpack response from dictionary and create one dataframe for each ranking and each keyword Source code in src\\data\\gtrends_extract.py def unpack_related_queries_response ( response ): \"\"\"Unpack response from dictionary and create one dataframe for each ranking and each keyword \"\"\" assert isinstance ( response , dict ), \"Empty response. Try again.\" ranking = [ * response [[ * response ][ 0 ]]] keywords = [ * response ] return response , ranking , keywords Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#code-reference","text":"","title":"Code reference"},{"location":"#google-results-count","text":"Extract results count from Google with beautiful soup Methods take a list of keywords and return a dataframe.","title":"Google results count"},{"location":"#src.data.gresults_extract.assert_google_results","text":"Ensures that dataframe meets expectations Source code in src\\data\\gresults_extract.py def assert_google_results ( df , keyword_list , url = \"https://www.google.com/search?q=\" ): \"\"\"Ensures that dataframe meets expectations \"\"\" # expected dataframe for comparison df_compare = pd . DataFrame ({ 'keyword' : pd . Series ([ * keyword_list ], dtype = 'object' ), 'results_count' : pd . Series ([ 1 for i in keyword_list ], dtype = 'int64' ), 'search_url' : pd . Series ( create_search_url ( keyword_list , url = url ), dtype = 'object' ), 'query_timestamp' : pd . Series ([ datetime . now () for i in keyword_list ], dtype = 'datetime64[ns]' ) }) # comparison to actual column_difference = set ( df . columns ) . symmetric_difference ( df_compare . columns ) assert len ( column_difference ) == 0 , f \"The following columns differ to reference dataframe: { column_difference } \" assert ( df_compare . dtypes == df . dtypes ) . all (), f \"Different dtypes for { df . dtypes } \\n { df_compare . dtypes } \" assert len ( df ) == len ( keyword_list ), f \" { len ( df ) } does not equal { len ( keyword_list ) } \" logging . info ( \"Google results data meets expectations\" )","title":"assert_google_results()"},{"location":"#src.data.gresults_extract.create_search_url","text":"Create Google search URL for a keyword from keyword_list Parameters: Name Type Description Default keyword_list list list of strings that contain the search keywords required url str Google's base search url 'https://www.google.com/search?q=' Returns: Type Description list Google search url like https://www.google.com/search?q=pizza Source code in src\\data\\gresults_extract.py def create_search_url ( keyword_list , url = \"https://www.google.com/search?q=\" ): \"\"\"Create Google search URL for a keyword from keyword_list Args: keyword_list (list): list of strings that contain the search keywords url (str): Google's base search url Returns: list: Google search url like https://www.google.com/search?q=pizza \"\"\" search_query = [ kw . replace ( ' ' , '+' ) for kw in keyword_list ] # replace space with '+' return [ url + sq for sq in search_query ]","title":"create_search_url()"},{"location":"#src.data.gresults_extract.get_results_count","text":"Gets Google's result count for a keyword Parameters: Name Type Description Default keyword string The keyword for which to get the results count required user_agent string For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} required Returns: Type Description int Results count Source code in src\\data\\gresults_extract.py def get_results_count ( keyword , user_agent ): \"\"\"Gets Google's result count for a keyword Args: keyword (string): The keyword for which to get the results count user_agent (string): For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} Returns: int: Results count \"\"\" result = requests . get ( keyword , headers = user_agent ) soup = BeautifulSoup ( result . content , 'html.parser' ) # string that contains results count 'About 1,410,000,000 results' total_results_text = soup . find ( \"div\" , { \"id\" : \"result-stats\" }) . find ( text = True , recursive = False ) # extract number results_num = int ( '' . join ([ num for num in total_results_text if num . isdigit ()]) ) return results_num","title":"get_results_count()"},{"location":"#src.data.gresults_extract.get_results_count_pipeline","text":"Google results count for each keyword of keyword_list in a dataframe Parameters: Name Type Description Default keyword_list list The keywords for which to get the results count required user_agent string For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} required url string Google's base search URL like \"https://www.google.com/search?q=\" (default) 'https://www.google.com/search?q=' Returns: Type Description dataframe Google results count and query metadata Examples: with open('../settings.yaml') as file: config = yaml.full_load(file) user_agent = config['query']['google_results']['user_agent'] base_url = config['query']['google_results']['base_url'] keyword_list = ['pizza', 'lufthansa'] result_counts = get_results_count_pipeline(keyword_list, user_agent, base_url) Source code in src\\data\\gresults_extract.py def get_results_count_pipeline ( keyword_list , user_agent , url = \"https://www.google.com/search?q=\" ): \"\"\"Google results count for each keyword of keyword_list in a dataframe Args: keyword_list (list): The keywords for which to get the results count user_agent (string): For example {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"} url (string): Google's base search URL like \"https://www.google.com/search?q=\" (default) Returns: dataframe: Google results count and query metadata Examples: with open('../settings.yaml') as file: config = yaml.full_load(file) user_agent = config['query']['google_results']['user_agent'] base_url = config['query']['google_results']['base_url'] keyword_list = ['pizza', 'lufthansa'] result_counts = get_results_count_pipeline(keyword_list, user_agent, base_url) \"\"\" search_urls = create_search_url ( keyword_list ) result_count = [ get_results_count ( url , user_agent ) for url in search_urls ] df = pd . DataFrame ({ 'keyword' : keyword_list , 'results_count' : result_count , 'search_url' : search_urls , 'query_timestamp' : datetime . now ()}) # testing assert_google_results ( df = df , keyword_list = keyword_list , url = url ) return df","title":"get_results_count_pipeline()"},{"location":"#google-trends","text":"Extract data from Google trends with the pytrends package methods take one keyword, call pytrends and return raw data","title":"Google trends"},{"location":"#src.data.gtrends_extract.create_pytrends_session","text":"Create pytrends TrendReq() session on which .build_payload() can be called Source code in src\\data\\gtrends_extract.py def create_pytrends_session (): \"\"\"Create pytrends TrendReq() session on which .build_payload() can be called \"\"\" pytrends_session = TrendReq () return pytrends_session","title":"create_pytrends_session()"},{"location":"#src.data.gtrends_extract.create_related_queries_dataframe","text":"Returns a single dataframe of related queries for a list of keywords and each ranking (either 'top' or 'rising') Source code in src\\data\\gtrends_extract.py def create_related_queries_dataframe ( response , rankings , keywords , geo_description = 'global' ): \"\"\"Returns a single dataframe of related queries for a list of keywords and each ranking (either 'top' or 'rising') \"\"\" df_list = [] for r in rankings : for kw in keywords : df_list . append ( process_response ( response , kw = kw , ranking = r , geo = geo_description )) return pd . concat ( df_list )","title":"create_related_queries_dataframe()"},{"location":"#src.data.gtrends_extract.get_related_queries","text":"Returns a dictionary with a dataframe for each keyword Calls pytrend's related_queries() Parameters: Name Type Description Default pytrends_session object TrendReq() session of pytrend required keyword_list list Used as input for query and passed to TrendReq().build_payload() required cat int see https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories 0 geo str Geolocation like US, UK '' Returns: Type Description Dictionary Dict with dataframes with related query results Source code in src\\data\\gtrends_extract.py def get_related_queries ( pytrends_session , keyword_list , cat = 0 , geo = '' ): \"\"\"Returns a dictionary with a dataframe for each keyword Calls pytrend's related_queries() Args: pytrends_session (object): TrendReq() session of pytrend keyword_list (list): Used as input for query and passed to TrendReq().build_payload() cat (int): see https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories geo (str): Geolocation like US, UK Returns: Dictionary: Dict with dataframes with related query results \"\"\" assert isinstance ( keyword_list , list ), f \"keyword_list should be string. Instead of type { type ( keyword_list ) } \" df_related_queries = pd . DataFrame () try : pytrends_session . build_payload ( keyword_list , cat = cat , geo = geo ) df_related_queries = pytrends_session . related_queries () logging . info ( f \"Query succeeded for { * keyword_list , } \" ) except Exception as e : logging . error ( f \"Query not unsuccessful due to { e } . Return empty DataFrame.\" ) return df_related_queries","title":"get_related_queries()"},{"location":"#src.data.gtrends_extract.get_related_queries_pipeline","text":"Returns all response data for pytrend's .related_queries() in a single dataframe Example usage: pytrends_session = create_pytrends_session() df = get_related_queries_pipeline(pytrends_session, keyword_list=['pizza', 'lufthansa']) Source code in src\\data\\gtrends_extract.py def get_related_queries_pipeline ( pytrends_session , keyword_list , cat = 0 , geo = '' , geo_description = 'global' ): \"\"\"Returns all response data for pytrend's .related_queries() in a single dataframe Example usage: pytrends_session = create_pytrends_session() df = get_related_queries_pipeline(pytrends_session, keyword_list=['pizza', 'lufthansa']) \"\"\" response = get_related_queries ( pytrends_session = pytrends_session , keyword_list = keyword_list , cat = cat , geo = geo ) # response , rankings , keywords = unpack_related_queries_response ( response = response ) df_trends = create_related_queries_dataframe ( response = response , rankings = rankings , keywords = keywords , geo_description = geo_description ) return df_trends","title":"get_related_queries_pipeline()"},{"location":"#src.data.gtrends_extract.process_response","text":"Helper function for unpack_related_queries_response() Source code in src\\data\\gtrends_extract.py def process_response ( response , kw , geo , ranking ): \"\"\" Helper function for unpack_related_queries_response() \"\"\" try : df = response [ kw ][ ranking ] df [[ 'keyword' , 'ranking' , 'geo' , 'query_timestamp' ]] = [ kw , ranking , geo , datetime . now ()] except : logging . info ( f \"Append empty dataframe for { ranking } : { kw } \" ) return pd . DataFrame ( columns = [ 'query' , 'value' , 'keyword' , 'ranking' , 'geo' , 'query_timestamp' ]) return df","title":"process_response()"},{"location":"#src.data.gtrends_extract.unpack_related_queries_response","text":"Unpack response from dictionary and create one dataframe for each ranking and each keyword Source code in src\\data\\gtrends_extract.py def unpack_related_queries_response ( response ): \"\"\"Unpack response from dictionary and create one dataframe for each ranking and each keyword \"\"\" assert isinstance ( response , dict ), \"Empty response. Try again.\" ranking = [ * response [[ * response ][ 0 ]]] keywords = [ * response ] return response , ranking , keywords","title":"unpack_related_queries_response()"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"}]}